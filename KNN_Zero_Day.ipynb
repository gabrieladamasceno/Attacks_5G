{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrieladamasceno/Attacks_5G/blob/main/KNN_Zero_Day.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuurjZdWJk6h",
        "outputId": "6c7c0f31-bf9e-4f03-ba9d-37aff96bae8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Acessar dataset\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Carregar o dataset\n",
        "encoded = pd.read_csv(\"/content/gdrive/MyDrive/Datasets/Attacks/Encoded/Encoded.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "7VCtN5o8jsGr"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biNnSG49XmU0",
        "outputId": "477efbaf-da95-4aa4-b926-495c8362afe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de amostras: 1215890\n",
            "Número de amostras (usando len): 1215890\n"
          ]
        }
      ],
      "source": [
        "# Usando shape\n",
        "num_amostras = encoded.shape[0]\n",
        "print(f\"Número de amostras: {num_amostras}\")\n",
        "\n",
        "# Usando len()\n",
        "num_amostras_len = len(encoded)\n",
        "print(f\"Número de amostras (usando len): {num_amostras_len}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULAbhjQIYl8b",
        "outputId": "1f70e61b-6eb9-4f20-c43b-1f7dbcaabc0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nomes das colunas:\n",
            "Unnamed: 0\n",
            "Seq\n",
            "Dur\n",
            "RunTime\n",
            "Mean\n",
            "Sum\n",
            "Min\n",
            "Max\n",
            "sTos\n",
            "dTos\n",
            "sTtl\n",
            "dTtl\n",
            "sHops\n",
            "dHops\n",
            "TotPkts\n",
            "SrcPkts\n",
            "DstPkts\n",
            "TotBytes\n",
            "SrcBytes\n",
            "DstBytes\n",
            "Offset\n",
            "sMeanPktSz\n",
            "dMeanPktSz\n",
            "Load\n",
            "SrcLoad\n",
            "DstLoad\n",
            "Loss\n",
            "SrcLoss\n",
            "DstLoss\n",
            "pLoss\n",
            "SrcGap\n",
            "DstGap\n",
            "Rate\n",
            "SrcRate\n",
            "DstRate\n",
            "SrcWin\n",
            "DstWin\n",
            "sVid\n",
            "dVid\n",
            "SrcTCPBase\n",
            "DstTCPBase\n",
            "TcpRtt\n",
            "SynAck\n",
            "AckDat\n",
            "Label\n",
            "Attack Type\n",
            "Attack Tool\n",
            " *        \n",
            " *    V   \n",
            " *    f   \n",
            " e        \n",
            " e    f   \n",
            " e &      \n",
            " e *      \n",
            " e d      \n",
            " e g      \n",
            " e i      \n",
            " e r      \n",
            " e s      \n",
            " eU       \n",
            "e        \n",
            "arp\n",
            "icmp\n",
            "ipv6-icmp\n",
            "llc\n",
            "lldp\n",
            "sctp\n",
            "tcp\n",
            "udp\n",
            "ACC\n",
            "CON\n",
            "ECO\n",
            "FIN\n",
            "INT\n",
            "NRS\n",
            "REQ\n",
            "RSP\n",
            "RST\n",
            "TST\n",
            "URP\n",
            "Shutdown\n",
            "Start\n",
            "Status\n",
            "39\n",
            "4\n",
            "52\n",
            "54\n",
            "af11\n",
            "af12\n",
            "af41\n",
            "cs0\n",
            "cs4\n",
            "cs6\n",
            "cs7\n",
            "ef\n",
            "nan\n"
          ]
        }
      ],
      "source": [
        "# Exibir os nomes de todas as colunas\n",
        "colunas = encoded.columns.tolist()  # Converte o Index em uma lista\n",
        "print(\"Nomes das colunas:\")\n",
        "for coluna in colunas:\n",
        "    print(coluna)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecionar apenas colunas numéricas\n",
        "numeric_cols = encoded.select_dtypes(include=['number']).columns\n",
        "\n",
        "# Aplicar a suavização apenas nas colunas numéricas\n",
        "for col in numeric_cols:\n",
        "    encoded[col] = encoded[col].fillna(encoded[col].mean())"
      ],
      "metadata": {
        "id": "F7xFWWJ6f72N"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# columns with null values\n",
        "\n",
        "columns_null = []\n",
        "columns = encoded.columns\n",
        "for column in columns:\n",
        "    c = encoded[column].isnull().sum()\n",
        "    if c != 0:\n",
        "        print(column, 'has {} null values'.format(c))\n",
        "        columns_null.append(column)"
      ],
      "metadata": {
        "id": "MTktQ-fDi4cS"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REG482ke4ujI"
      },
      "source": [
        "Features\n",
        "* Seq: Sequência de pacotes.\n",
        "* Offset: Deslocamento em bytes.\n",
        "* sTtl: Time to Live da fonte.\n",
        "* tcp: Indica se o protocolo TCP está sendo usado.\n",
        "* AckDat: Dados de reconhecimento.\n",
        "* RST: Sinalizador de reinício TCP.\n",
        "* INT: Interrupções no fluxo de dados.\n",
        "* TcpRtt: Tempo de ida e volta do TCP.\n",
        "* icmp: Indica se o protocolo ICMP está presente.\n",
        "* sMeanPktSz: Tamanho médio do pacote da fonte.\n",
        "* FIN: Sinalizador de finalização de conexão.\n",
        "* sHops: Número de saltos até o destino.\n",
        "* Mean: Valor médio de um conjunto de dados.\n",
        "* dTtl: Time to Live do destino.\n",
        "* SrcBytes: Bytes enviados da fonte.\n",
        "* TotBytes: Total de bytes.\n",
        "* dMeanPktSz: Tamanho médio do pacote do destino.\n",
        "* Status: Estado da conexão.\n",
        "* cs0: Parâmetro de controle.\n",
        "* SrcWin: Janela de origem TCP.\n",
        "* sTos: Tipo de serviço.\n",
        "* CON: Conexões.\n",
        "* REQ: Requisições.\n",
        "* Loss: Taxa de perda de pacotes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Selecionar apenas as colunas 'Label' e 'Attack Type'\n",
        "icmp_flood_samples = encoded[['Label', 'icmp', 'Attack Type']]\n",
        "\n",
        "icmp_flood_samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "K0q9lfe5EWEK",
        "outputId": "4ce7851a-ee94-4a6d-84ec-74991b5a0b17"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Label  icmp Attack Type\n",
              "0        Benign   1.0      Benign\n",
              "1        Benign   1.0      Benign\n",
              "2        Benign   0.0      Benign\n",
              "3        Benign   0.0      Benign\n",
              "4        Benign   0.0      Benign\n",
              "...         ...   ...         ...\n",
              "1215885  Benign   0.0      Benign\n",
              "1215886  Benign   0.0      Benign\n",
              "1215887  Benign   0.0      Benign\n",
              "1215888  Benign   0.0      Benign\n",
              "1215889  Benign   0.0      Benign\n",
              "\n",
              "[1215890 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bdad2dba-7cf4-4629-996a-80d313357c2c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>icmp</th>\n",
              "      <th>Attack Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Benign</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Benign</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Benign</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Benign</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Benign</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1215885</th>\n",
              "      <td>Benign</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1215886</th>\n",
              "      <td>Benign</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1215887</th>\n",
              "      <td>Benign</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1215888</th>\n",
              "      <td>Benign</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1215889</th>\n",
              "      <td>Benign</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1215890 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdad2dba-7cf4-4629-996a-80d313357c2c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bdad2dba-7cf4-4629-996a-80d313357c2c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bdad2dba-7cf4-4629-996a-80d313357c2c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c64bb25e-3617-4814-9a8f-d60b0fc0c47b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c64bb25e-3617-4814-9a8f-d60b0fc0c47b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c64bb25e-3617-4814-9a8f-d60b0fc0c47b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f7957cea-91ab-4ace-8265-75deefa051cf\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('icmp_flood_samples')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f7957cea-91ab-4ace-8265-75deefa051cf button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('icmp_flood_samples');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "icmp_flood_samples"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import time\n",
        "from keras.callbacks import Callback\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Função para monitorar recursos\n",
        "def monitor_resource_usage():\n",
        "    process = psutil.Process()\n",
        "    memory_info = process.memory_info()\n",
        "    cpu_percent = psutil.cpu_percent(interval=0.1)\n",
        "    memory_usage_mb = memory_info.rss / (1024 * 1024)\n",
        "    return cpu_percent, memory_usage_mb\n",
        "\n",
        "# Callback personalizado para monitorar CPU e memória\n",
        "class ResourceMonitor(Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        # Antes da época começar\n",
        "        self.start_time = time.time()\n",
        "        self.start_cpu, self.start_memory = monitor_resource_usage()\n",
        "        print(f\"\\n[Início da Época {epoch + 1}]\")\n",
        "        print(f\"CPU inicial: {self.start_cpu:.2f}%, Memória inicial: {self.start_memory:.2f} MB\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Após a época terminar\n",
        "        end_time = time.time()\n",
        "        end_cpu, end_memory = monitor_resource_usage()\n",
        "        elapsed_time = end_time - self.start_time\n",
        "        memory_diff = end_memory - self.start_memory\n",
        "\n",
        "        print(f\"[Fim da Época {epoch + 1}]\")\n",
        "        print(f\"CPU final: {end_cpu:.2f}%, Memória consumida: {memory_diff:.2f} MB, Tempo gasto: {elapsed_time:.2f} segundos\")\n",
        "\n",
        "# Instanciar o callback\n",
        "resource_monitor = ResourceMonitor()\n",
        "\n",
        "# Parâmetros para early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)"
      ],
      "metadata": {
        "id": "s4yCHc3I-s6b"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Configuração das features e rótulos\n",
        "features = [\n",
        "    'Seq', 'Offset', 'sTtl', 'tcp', 'AckDat', 'RST', 'INT', 'TcpRtt', 'icmp',\n",
        "    'sMeanPktSz', 'FIN', 'sHops', 'Mean', 'dTtl', 'SrcBytes', 'TotBytes',\n",
        "    'dMeanPktSz', 'Status', 'cs0', 'SrcWin', 'sTos', 'CON', 'REQ', 'Loss', 'Attack Type'\n",
        "]\n",
        "\n",
        "X = encoded[features]\n",
        "y = encoded['Label']  # Coluna de rótulos\n",
        "\n",
        "# Divida os dados normalmente\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Identifique as amostras ICMPFlood no conjunto de treino\n",
        "train_zero_day_indices = X_train[X_train['Attack Type'] == 'ICMPFlood'].index\n",
        "\n",
        "# Remova essas amostras de ICMPFlood do conjunto de treino\n",
        "X_train_clean = X_train.drop(train_zero_day_indices)\n",
        "y_train_clean = y_train.drop(train_zero_day_indices)\n",
        "\n",
        "# Identifique as amostras ICMPFlood no conjunto de teste\n",
        "test_zero_day_indices = X_test[X_test['Attack Type'] == 'ICMPFlood'].index\n",
        "\n",
        "# Mantenha as amostras de ICMPFlood no conjunto de teste\n",
        "X_test_zero_day = X_test.loc[test_zero_day_indices]\n",
        "y_test_zero_day = y_test.loc[test_zero_day_indices]\n",
        "\n",
        "# Verificar a distribuição das classes no conjunto de teste\n",
        "print(f\"Zero-day presente no conjunto de teste: {any(test_zero_day_indices.isin(X_test_zero_day.index))} \\n\")\n",
        "\n",
        "# Verificar as distribuições\n",
        "print(\"Distribuição do conjunto de treino binário:\", pd.Series(y_train_clean).value_counts())\n",
        "print(\"Distribuição do conjunto de teste binário:\", pd.Series(y_test_zero_day).value_counts())\n",
        "\n",
        "# Remover a coluna 'Attack Type' das features de treino e teste\n",
        "X_train_clean = X_train_clean.drop(columns=['Attack Type'])\n",
        "X_test = X_test.drop(columns=['Attack Type'])\n",
        "X_test_zero_day = X_test_zero_day.drop(columns=['Attack Type'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xisgI82tprr",
        "outputId": "bdb06900-102f-4ed1-b944-a26ec77869a3"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-day presente no conjunto de teste: True \n",
            "\n",
            "Distribuição do conjunto de treino binário: Label\n",
            "Malicious    589852\n",
            "Benign       381943\n",
            "Name: count, dtype: int64\n",
            "Distribuição do conjunto de teste binário: Label\n",
            "Malicious    238\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "NPw0TKwtMs2K",
        "outputId": "3d81f95c-6989-4cc6-8485-76654e1a7805"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "873982     Malicious\n",
              "617114     Malicious\n",
              "874834     Malicious\n",
              "1065744       Benign\n",
              "876351     Malicious\n",
              "             ...    \n",
              "818966     Malicious\n",
              "1166938       Benign\n",
              "669203        Benign\n",
              "948209     Malicious\n",
              "722836        Benign\n",
              "Name: Label, Length: 243178, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>873982</th>\n",
              "      <td>Malicious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>617114</th>\n",
              "      <td>Malicious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>874834</th>\n",
              "      <td>Malicious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1065744</th>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>876351</th>\n",
              "      <td>Malicious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>818966</th>\n",
              "      <td>Malicious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1166938</th>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669203</th>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>948209</th>\n",
              "      <td>Malicious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>722836</th>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>243178 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "\n",
        "# Configurar o SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# Aplicar SMOTE no conjunto de treinamento\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_clean, y_train_clean)\n",
        "\n",
        "# Verificar distribuição das classes após o SMOTE\n",
        "print(f\"Distribuição após SMOTE:\\n{pd.Series(y_train_balanced).value_counts()}\")\n",
        "\n",
        "# Normalizar os dados após o SMOTE\n",
        "scaler = StandardScaler()\n",
        "X_train_balanced = scaler.fit_transform(X_train_balanced)\n",
        "\n",
        "# Normalizar o conjunto de teste com o mesmo scaler ajustado no treino\n",
        "X_test_combined = scaler.transform(X_test)\n",
        "y_test_combined = y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7CTpEG903J5",
        "outputId": "27c81802-2e90-4c12-d529-94f4ff28bb74"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribuição após SMOTE:\n",
            "Label\n",
            "Malicious    589852\n",
            "Benign       589852\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar a dimensão do treino sem balancear\n",
        "#print(X_train_non_zero_day.shape)\n",
        "#print(y_train_non_zero_day.shape)\n",
        "#print(f\"Distribuição sem balancear:\\n{pd.Series(y_train_non_zero_day).value_counts()}\")\n",
        "\n",
        "# Verificar a dimensão do teste\n",
        "print(X_test_combined.shape)\n",
        "print(y_test_combined.shape)\n",
        "print(f\"Distribuição Teste:\\n{pd.Series(y_test_combined).value_counts()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZy0q2ZFIgc3",
        "outputId": "3dcd6585-7087-4f1e-aecc-8d16727e06fa"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(243178, 24)\n",
            "(243178,)\n",
            "Distribuição Teste:\n",
            "Label\n",
            "Malicious    147384\n",
            "Benign        95794\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Criar o codificador\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Ajustar o codificador aos rótulos de treinamento e teste\n",
        "y_train_balanced = label_encoder.fit_transform(y_train_balanced)\n",
        "y_test_combined = label_encoder.transform(y_test_combined)\n",
        "\n",
        "# Verificar os tipos após a transformação\n",
        "print(y_train_balanced.dtype)\n",
        "print(y_test_combined.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ph39Wxjncpv",
        "outputId": "39e9fed7-c934-440e-eb4f-3cc6d4b410dd"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "int64\n",
            "int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Configuração do modelo KNN\n",
        "k = 10  # Número de vizinhos\n",
        "knn_model = KNeighborsClassifier(n_neighbors=k, weights='uniform', metric='euclidean')\n",
        "\n",
        "# Monitorar antes e depois do treinamento\n",
        "print(\"[Monitoramento de Recursos durante o ajuste do modelo KNN]\")\n",
        "start_cpu, start_memory = monitor_resource_usage()\n",
        "start_time = time.time()\n",
        "\n",
        "# Treinar o modelo KNN\n",
        "knn_model.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "end_cpu, end_memory = monitor_resource_usage()\n",
        "end_time = time.time()\n",
        "\n",
        "# Exibir informações de uso de recursos\n",
        "print(f\"CPU inicial: {start_cpu:.2f}%, Memória inicial: {start_memory:.2f} MB\")\n",
        "print(f\"CPU final: {end_cpu:.2f}%, Memória final: {end_memory:.2f} MB\")\n",
        "print(f\"Memória consumida: {end_memory - start_memory:.2f} MB\")\n",
        "print(f\"Tempo total: {end_time - start_time:.2f} segundos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT-u-oDLAyZJ",
        "outputId": "7f62a1ed-7882-4dad-dfb5-deab48bce625"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Monitoramento de Recursos durante o ajuste do modelo KNN]\n",
            "CPU inicial: 1.70%, Memória inicial: 6326.14 MB\n",
            "CPU final: 1.80%, Memória final: 6542.04 MB\n",
            "Memória consumida: 215.90 MB\n",
            "Tempo total: 0.22 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Monitorar durante a predição\n",
        "print(\"[Monitoramento de Recursos durante a predição]\")\n",
        "start_cpu, start_memory = monitor_resource_usage()\n",
        "start_time = time.time()\n",
        "\n",
        "y_pred = knn_model.predict(X_test_combined)\n",
        "\n",
        "end_cpu, end_memory = monitor_resource_usage()\n",
        "end_time = time.time()\n",
        "\n",
        "# Exibir informações de uso de recursos\n",
        "print(f\"CPU inicial: {start_cpu:.2f}%, Memória inicial: {start_memory:.2f} MB\")\n",
        "print(f\"CPU final: {end_cpu:.2f}%, Memória final: {end_memory:.2f} MB\")\n",
        "print(f\"Memória consumida: {end_memory - start_memory:.2f} MB\")\n",
        "print(f\"Tempo total: {end_time - start_time:.2f} segundos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGAj8kcYBfHP",
        "outputId": "3ae47b10-3d1c-408a-dacd-dd4f72c0faf3"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Monitoramento de Recursos durante a predição]\n",
            "CPU inicial: 2.00%, Memória inicial: 6542.04 MB\n",
            "CPU final: 0.20%, Memória final: 6542.04 MB\n",
            "Memória consumida: 0.00 MB\n",
            "Tempo total: 47.25 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Definindo o classificador\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Suponha que X_train_clean e y_train_clean sejam seus dados de treinamento\n",
        "# Calculando múltiplas métricas com 5-fold cross-validation\n",
        "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
        "results = cross_validate(knn, X_train_clean, y_train_clean, cv=5, scoring=scoring)\n",
        "\n",
        "# Exibindo os resultados para cada fold\n",
        "print(\"Acurácia para cada fold:\", results['test_accuracy'])\n",
        "print(\"Precisão para cada fold:\", results['test_precision'])\n",
        "print(\"Recall para cada fold:\", results['test_recall'])\n",
        "print(\"F1-score para cada fold:\", results['test_f1'])\n",
        "\n",
        "# Média das métricas\n",
        "print(\"Acurácia média:\", results['test_accuracy'].mean())\n",
        "print(\"Precisão média:\", results['test_precision'].mean())\n",
        "print(\"Recall médio:\", results['test_recall'].mean())\n",
        "print(\"F1-score médio:\", results['test_f1'].mean())\n",
        "\n",
        "# Agora, realizando a previsão e convertendo para 'Benign'/'Malicious'\n",
        "y_pred = knn.predict(X_test_clean)  # Suponha que X_test_clean seja o conjunto de teste\n",
        "y_pred = ['Benign' if label == 0 else 'Malicious' for label in y_pred]\n",
        "\n",
        "# Calculando a precisão usando a conversão correta para 'Malicious'\n",
        "precision = precision_score(y_test, y_pred, pos_label='Malicious')  # ou 'Benign', dependendo do caso\n",
        "print(\"Precisão no conjunto de teste:\", precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U48HD5xUOHAq",
        "outputId": "685d6148-cc42-48b5-d096-4b4643be8dd7"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 2247, in precision_score\n",
            "    p, _, _, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1830, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1604, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['Benign', 'Malicious']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 2429, in recall_score\n",
            "    _, r, _, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1830, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1604, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['Benign', 'Malicious']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1324, in f1_score\n",
            "    return fbeta_score(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1517, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1830, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1604, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['Benign', 'Malicious']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 2247, in precision_score\n",
            "    p, _, _, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1830, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1604, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['Benign', 'Malicious']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 2429, in recall_score\n",
            "    _, r, _, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1830, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1604, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['Benign', 'Malicious']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1324, in f1_score\n",
            "    return fbeta_score(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1517, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1830, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1604, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['Benign', 'Malicious']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 2247, in precision_score\n",
            "    p, _, _, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1830, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1604, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['Benign', 'Malicious']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 2429, in recall_score\n",
            "    _, r, _, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1830, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1604, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['Benign', 'Malicious']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1324, in f1_score\n",
            "    return fbeta_score(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1517, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1830, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1604, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['Benign', 'Malicious']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 2247, in precision_score\n",
            "    p, _, _, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1830, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1604, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['Benign', 'Malicious']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 2429, in recall_score\n",
            "    _, r, _, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1830, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1604, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['Benign', 'Malicious']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1324, in f1_score\n",
            "    return fbeta_score(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1517, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1830, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1604, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['Benign', 'Malicious']\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia para cada fold: [0.98763628 0.98753852 0.98776491 0.9877752  0.98769802]\n",
            "Precisão para cada fold: [nan nan nan nan nan]\n",
            "Recall para cada fold: [nan nan nan nan nan]\n",
            "F1-score para cada fold: [nan nan nan nan nan]\n",
            "Acurácia média: 0.9876825873769673\n",
            "Precisão média: nan\n",
            "Recall médio: nan\n",
            "F1-score médio: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 2247, in precision_score\n",
            "    p, _, _, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1830, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1604, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['Benign', 'Malicious']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 2429, in recall_score\n",
            "    _, r, _, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1830, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1604, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['Benign', 'Malicious']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1324, in f1_score\n",
            "    return fbeta_score(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1517, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1830, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1604, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['Benign', 'Malicious']\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_test_clean' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-e7d8e9f9d6d4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Agora, realizando a previsão e convertendo para 'Benign'/'Malicious'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_clean\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Suponha que X_test_clean seja o conjunto de teste\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Benign'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'Malicious'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test_clean' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Suponha que X_train e y_train sejam seus dados de treinamento\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Calculando a AUC com 5-fold cross-validation\n",
        "auc_scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='roc_auc')\n",
        "\n",
        "print(\"AUC para cada fold:\", auc_scores)\n",
        "print(\"AUC média:\", auc_scores.mean())"
      ],
      "metadata": {
        "id": "HJkZF73Pe2WB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliar o desempenho do modelo\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test_combined, y_pred))\n",
        "\n",
        "# Matriz de Confusão\n",
        "cm = confusion_matrix(y_test_combined, y_pred)\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "print(cm)\n",
        "\n",
        "# Opcional: Visualizar a matriz de confusão\n",
        "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_).plot(cmap='Blues')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-3zZ6hnGAzHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_zero_day_no_names = X_test_zero_day.values\n",
        "\n",
        "y_pred_zero_day = knn_model.predict(X_test_zero_day_no_names)"
      ],
      "metadata": {
        "id": "1ja0JduJDb0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifique se as dimensões de X_test_zero_day e y_test_zero_day são consistentes\n",
        "print(f\"Tamanho de X_test_zero_day: {X_test_zero_day.shape}\")\n",
        "print(f\"Tamanho de y_test_zero_day: {y_test_zero_day.shape}\")\n"
      ],
      "metadata": {
        "id": "NP2-GNmBD2bN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prever com o modelo para as amostras zero-day\n",
        "y_pred_zero_day = knn_model.predict(X_test_zero_day)\n",
        "\n",
        "# Verifique as previsões\n",
        "print(f\"Previsões para as amostras zero-day: {y_pred_zero_day}\")\n",
        "\n",
        "# Verifique se as previsões estão corretas (se a classe de 'maligno' é representada como 1)\n",
        "accuracy_zero_day = (y_pred_zero_day == 1).mean()  # Supondo que '1' é a classe de maligno\n",
        "print(f\"Acurácia para zero-day: {accuracy_zero_day * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "FsDzBxUcNYyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparando previsões com os rótulos reais\n",
        "correct_classifications = (y_pred_zero_day == y_test_zero_day).sum()\n",
        "total_zero_day_samples = len(y_test_zero_day)\n",
        "\n",
        "print(f\"Amostras zero-day classificadas corretamente: {correct_classifications}/{total_zero_day_samples}\")\n",
        "print(f\"Taxa de acerto para as amostras zero-day: {correct_classifications / total_zero_day_samples * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "rMezPZvPNdzY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}