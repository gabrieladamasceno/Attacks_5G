{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrieladamasceno/Attacks_5G/blob/main/Random_Forest_All_Attacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuurjZdWJk6h",
        "outputId": "eb508b02-7576-4eef-ef5d-56789ddfca9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Acessar dataset\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Carregar o dataset\n",
        "encoded = pd.read_csv(\"/content/gdrive/MyDrive/Datasets/Attacks/Encoded/Encoded.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S3nVM7mjjwA",
        "outputId": "8c01d23e-e498-4146-fcba-a7a4b54e2e54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "pip install imbalanced-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRYPuBoL3xT4",
        "outputId": "e0e774bb-62f7-41bf-980f-7b11984be91f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.20.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.12.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.12.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras) (0.5.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install --upgrade keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GghS26GFNafC",
        "outputId": "c16f6cee-aa0e-4542-9803-e3f5cd596996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.12/dist-packages (1.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gputil\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7xFWWJ6f72N"
      },
      "outputs": [],
      "source": [
        "# Selecionar apenas colunas numéricas\n",
        "numeric_cols = encoded.select_dtypes(include=['number']).columns\n",
        "\n",
        "# Aplicar a suavização apenas nas colunas numéricas\n",
        "for col in numeric_cols:\n",
        "    encoded[col] = encoded[col].fillna(encoded[col].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTktQ-fDi4cS"
      },
      "outputs": [],
      "source": [
        "# columns with null values\n",
        "\n",
        "columns_null = []\n",
        "columns = encoded.columns\n",
        "for column in columns:\n",
        "    c = encoded[column].isnull().sum()\n",
        "    if c != 0:\n",
        "        print(column, 'has {} null values'.format(c))\n",
        "        columns_null.append(column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4yCHc3I-s6b"
      },
      "outputs": [],
      "source": [
        "import psutil\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "import subprocess\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import Callback\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras import backend as K\n",
        "\n",
        "# ===== Função para monitorar CPU e memória =====\n",
        "def monitor_resource_usage():\n",
        "    process = psutil.Process()\n",
        "    memory_info = process.memory_info()\n",
        "    cpu_percent = psutil.cpu_percent(interval=0.1)\n",
        "    memory_usage_mb = memory_info.rss / (1024 * 1024)\n",
        "    return cpu_percent, memory_usage_mb\n",
        "\n",
        "def calcular_energia(cpu_usage, freq_ghz, tempo_exec_s, theta=1.0, z=1e-27):\n",
        "    freq_hz = freq_ghz * 1e9\n",
        "    carga = cpu_usage * theta * freq_hz\n",
        "    energia_joules = z * (carga ** 3) * tempo_exec_s\n",
        "    return energia_joules\n",
        "\n",
        "# ===== Callback para monitoramento durante o treinamento =====\n",
        "class ResourceMonitor(Callback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.cpu_usage = []\n",
        "        self.memory_usage = []\n",
        "        self.energy_usage = []\n",
        "        self.start_time = time.time()\n",
        "        print(\"\\n[Início do Treinamento]\")\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        cpu, mem = monitor_resource_usage()\n",
        "        self.cpu_usage.append(cpu)\n",
        "        self.memory_usage.append(mem)\n",
        "        print(f\"\\n[Epoch {epoch + 1} - Início] CPU: {cpu:.2f}%, Memory: {mem:.2f} MB\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        cpu, mem = monitor_resource_usage()\n",
        "        self.cpu_usage.append(cpu)\n",
        "        self.memory_usage.append(mem)\n",
        "        frequencia_cpu_ghz = 2.0\n",
        "        tempo_execucao_epoca = time.time() - self.start_time\n",
        "        #energy = calcular_energia(cpu, frequencia_cpu_ghz, tempo_execucao_epoca)\n",
        "        #self.energy_usage.append(energy)\n",
        "        print(f\"[Epoch {epoch + 1} - Fim] CPU: {cpu:.2f}%, Memory: {mem:.2f} MB\")\n",
        "\n",
        "        # Limpeza de recursos\n",
        "        gc.collect()\n",
        "        K.clear_session()\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        total_time = time.time() - self.start_time\n",
        "        avg_cpu = np.mean(self.cpu_usage)\n",
        "        avg_mem = np.mean(self.memory_usage)\n",
        "\n",
        "        frequencia_cpu_ghz = 2.0\n",
        "\n",
        "        # Cálculo de energia corrigido\n",
        "        energia = calcular_energia(avg_cpu, frequencia_cpu_ghz, total_time)\n",
        "\n",
        "        print(\"\\n[End of Training]\")\n",
        "        print(f\"Total time: {total_time:.2f} seconds\")\n",
        "        print(f\"Average CPU usage (Training): {avg_cpu:.2f}%\")\n",
        "        print(f\"Average memory usage (Training): {avg_mem:.2f} MB\")\n",
        "        print(f\"Estimated energy consumption: {energia:.2f} Joules\")\n",
        "\n",
        "        # Armazenar para uso externo\n",
        "        self.total_time = total_time\n",
        "        self.avg_cpu = avg_cpu\n",
        "        self.avg_mem = avg_mem\n",
        "        self.energia = energia\n",
        "\n",
        "        self._plot_usage()\n",
        "\n",
        "    def _plot_usage(self):\n",
        "        epochs = list(range(1, len(self.cpu_usage) + 1))\n",
        "\n",
        "        plt.figure(figsize=(14, 5))\n",
        "\n",
        "        # CPU\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(epochs, self.cpu_usage, marker='o', linestyle='-', color='tab:blue', label='CPU Usage')\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"CPU Usage (%)\")\n",
        "        plt.title(\"CPU Consumption (Train)\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Memória\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(epochs, self.memory_usage, marker='o', linestyle='-', color='tab:red', label='Memory Usage')\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Memory (MB)\")\n",
        "        plt.title(\"Memory Consumption (Train)\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"resource_usage_train.png\")\n",
        "        plt.show()\n",
        "        plt.clf()\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "# ===== Monitoramento durante o teste/predição =====\n",
        "def monitor_test_prediction(model, X_test):\n",
        "    cpu_usage_test = []\n",
        "    memory_usage_test = []\n",
        "\n",
        "    print(\"\\n[Início da Predição/Teste]\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    step_size = max(1, len(X_test) // 10)\n",
        "    for i in range(0, len(X_test), step_size):\n",
        "        end_i = min(i + step_size, len(X_test))\n",
        "        monitor_cpu, monitor_mem = monitor_resource_usage()\n",
        "        cpu_usage_test.append(monitor_cpu)\n",
        "        memory_usage_test.append(monitor_mem)\n",
        "        _ = model.predict(X_test[i:end_i])\n",
        "\n",
        "    total_time_test = time.time() - start_time\n",
        "    avg_cpu_test = np.mean(cpu_usage_test)\n",
        "    avg_mem_test = np.mean(memory_usage_test)\n",
        "\n",
        "    frequencia_cpu_ghz = 2.0\n",
        "\n",
        "    # Cálculo de energia\n",
        "    energia_test = calcular_energia(avg_cpu_test, frequencia_cpu_ghz, total_time_test)\n",
        "\n",
        "    print(\"\\n[End of Prediction/Test]\")\n",
        "    print(f\"Total time: {total_time_test:.2f} seconds\")\n",
        "    print(f\"Average CPU usage (Test): {avg_cpu_test:.2f}%\")\n",
        "    print(f\"Average memory usage (Test): {avg_mem_test:.2f} MB\")\n",
        "    print(f\"Estimated energy consumption: {energia_test:.2f} Joules\")\n",
        "\n",
        "    # Gráficos\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    # CPU\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(1, len(cpu_usage_test) + 1), cpu_usage_test, marker='o', linestyle='-', color='tab:blue', label='CPU Usage (Test)')\n",
        "    plt.xlabel(\"Prediction Block\")\n",
        "    plt.ylabel(\"CPU Usage (%)\")\n",
        "    plt.title(\"CPU Consumption (Test)\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Memória\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(1, len(memory_usage_test) + 1), memory_usage_test, marker='o', linestyle='-', color='tab:red', label='Memory Usage (Test)')\n",
        "    plt.xlabel(\"Prediction Block\")\n",
        "    plt.ylabel(\"Memory (MB)\")\n",
        "    plt.title(\"Memory Consumption (Test)\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"resource_usage_test.png\")\n",
        "    plt.show()\n",
        "    plt.clf()\n",
        "    plt.close()\n",
        "\n",
        "    return {\n",
        "    'total_time': total_time_test,\n",
        "    'avg_cpu': avg_cpu_test,\n",
        "    'avg_mem': avg_mem_test,\n",
        "    'energia': energia_test\n",
        "    }\n",
        "\n",
        "resource_monitor = ResourceMonitor()\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def monitor_train_generic(model, X_train, y_train, model_name=\"model\"):\n",
        "    print(f\"\\n[Início do Treinamento - {model_name}]\")\n",
        "    process = psutil.Process(os.getpid())\n",
        "\n",
        "    # Coleta inicial\n",
        "    cpu_start = process.cpu_percent(interval=None)\n",
        "    mem_start = process.memory_info().rss / (1024 * 1024)\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Treinamento — funciona para sklearn, CatBoost etc.\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Coleta final\n",
        "    cpu_end = process.cpu_percent(interval=None)\n",
        "    mem_end = process.memory_info().rss / (1024 * 1024)\n",
        "    end_time = time.time()\n",
        "\n",
        "    total_time = end_time - start_time\n",
        "    avg_cpu = (cpu_start + cpu_end) / 2\n",
        "    avg_mem = (mem_start + mem_end) / 2\n",
        "    freq_ghz = 2.0\n",
        "\n",
        "    # Reaproveita sua função de energia\n",
        "    energia = calcular_energia(avg_cpu, freq_ghz, total_time)\n",
        "\n",
        "    print(f\"[Fim do Treinamento - {model_name}]\")\n",
        "    print(f\"Tempo total: {total_time:.2f}s\")\n",
        "    print(f\"CPU média: {avg_cpu:.2f}%\")\n",
        "    print(f\"Memória média: {avg_mem:.2f} MB\")\n",
        "    print(f\"Energia estimada: {energia:.2e} Joules\")\n",
        "\n",
        "    return {\n",
        "        'total_time': total_time,\n",
        "        'avg_cpu': avg_cpu,\n",
        "        'avg_mem': avg_mem,\n",
        "        'energia': energia\n",
        "    }"
      ],
      "metadata": {
        "id": "fGV6EUq59MWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "9r0CesR3Fdjl",
        "outputId": "45472639-3240-4e81-b8ef-2616ff56544b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====== Zero-Day: ICMPFlood ======\n",
            "Total ICMPFlood no dataset original: 1155\n",
            "  em X_train antes da remoção: 917\n",
            "  em X_test antes: 238\n",
            "  moved_to_test (vai mover): 917\n",
            "  test_zero (já no teste): 238\n",
            "  Zero-Day combined total: 1155 (duplicadas exatas: 0)\n",
            "  Test full total: 244095\n",
            "\n",
            "[Início do Treinamento - Random Forest]\n",
            "[Fim do Treinamento - Random Forest]\n",
            "Tempo total: 134.64s\n",
            "CPU média: 49.90%\n",
            "Memória média: 3678.81 MB\n",
            "Energia estimada: 1.34e+08 Joules\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "y contains previously unseen labels: 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_map_to_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_map_to_integer\u001b[0;34m(values, uniques)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nandict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 1",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3211133576.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mmstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0my_pred_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_full_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0my_pred_full_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mmetrics_test_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonitor_test_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_full_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0macc_teste_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_full_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_full_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_map_to_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"y contains previously unseen labels: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_unknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: 1"
          ]
        }
      ],
      "source": [
        "# ===== IMPORTS =====\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import psutil\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "\n",
        "# Configuração das features e rótulos\n",
        "features = [\n",
        "    'Seq', 'Offset', 'sTtl', 'tcp', 'AckDat', 'RST', 'INT', 'TcpRtt', 'icmp',\n",
        "    'sMeanPktSz', 'FIN', 'sHops', 'Mean', 'dTtl', 'SrcBytes', 'TotBytes',\n",
        "    'dMeanPktSz', 'Status', 'cs0', 'SrcWin', 'sTos', 'CON', 'REQ', 'Loss', 'Attack Type'\n",
        "]\n",
        "\n",
        "X = encoded[features]\n",
        "y = encoded['Label']  # Coluna de rótulos\n",
        "\n",
        "# Dividir antes de escolher zero-days\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Guardar Attack Type para separar os zero-days\n",
        "X_train['Attack Type'] = encoded.loc[X_train.index, 'Attack Type']\n",
        "X_test['Attack Type'] = encoded.loc[X_test.index, 'Attack Type']\n",
        "\n",
        "# ===== CONFIGURAÇÕES =====\n",
        "zero_day_attacks = ['ICMPFlood', 'UDPFlood', 'SYNFlood', 'SYNScan', 'HTTPFlood', 'UDPScan', 'TCPConnectScan', 'SlowrateDoS']  # Adapte para os ataques que você quiser testar\n",
        "smote = SMOTE(random_state=42)\n",
        "scaler = StandardScaler()\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "resultados_zero_day = []\n",
        "\n",
        "model_name = \"RandomForest\"\n",
        "roc_full_curves = []\n",
        "\n",
        "# ===== LOOP PRINCIPAL =====\n",
        "resultados_zero_day = []\n",
        "\n",
        "for ataque_zero_day in zero_day_attacks:\n",
        "    print(f\"\\n====== Zero-Day: {ataque_zero_day} ======\")\n",
        "\n",
        "# contagem global no dataset original (só pra referência)\n",
        "    total_in_original = (X['Attack Type'] == ataque_zero_day).sum()\n",
        "    print(f\"Total {ataque_zero_day} no dataset original: {total_in_original}\")\n",
        "\n",
        "    # --- Separação dos dados ---\n",
        "    train_indices = X_train[X_train['Attack Type'] != ataque_zero_day].index\n",
        "    test_indices = X_test[X_test['Attack Type'] == ataque_zero_day].index\n",
        "\n",
        "    # --- Amostras zero-day que estavam originalmente no treino (vai mover para o teste) ---\n",
        "    moved_to_test = X_train.loc[X_train['Attack Type'] == ataque_zero_day].copy()\n",
        "    moved_to_test_y = y_train.loc[moved_to_test.index].copy()\n",
        "\n",
        "    # debug counts\n",
        "    n_train_zero = len(moved_to_test)\n",
        "    n_test_zero = len(test_indices)\n",
        "    n_train_before = (X_train['Attack Type'] == ataque_zero_day).sum()\n",
        "    n_test_before = (X_test['Attack Type'] == ataque_zero_day).sum()\n",
        "    print(f\"  em X_train antes da remoção: {n_train_before}\")\n",
        "    print(f\"  em X_test antes: {n_test_before}\")\n",
        "    print(f\"  moved_to_test (vai mover): {n_train_zero}\")\n",
        "    print(f\"  test_zero (já no teste): {n_test_zero}\")\n",
        "\n",
        "    # --- Conjuntos limpos (sem o ataque zero-day no treino) ---\n",
        "    X_train_clean = X_train.loc[train_indices].drop(columns=['Attack Type']).copy()\n",
        "    y_train_clean = y_train.loc[train_indices].copy()\n",
        "\n",
        "    # --- Teste zero-day: inclui amostras do teste original + as movidas do treino ---\n",
        "    X_test_zero_day = pd.concat([\n",
        "        X_test.loc[test_indices].drop(columns=['Attack Type']).copy(),\n",
        "        moved_to_test.drop(columns=['Attack Type']).copy()\n",
        "    ], ignore_index=True)  # reset index para evitar sobreposição\n",
        "    y_test_zero_day = pd.concat([\n",
        "        y_test.loc[test_indices].copy(),\n",
        "        moved_to_test_y.copy()\n",
        "    ], ignore_index=True)\n",
        "\n",
        "    # --- Teste completo: todo o X_test original + as amostras movidas do treino ---\n",
        "    X_test_full = pd.concat([\n",
        "        X_test.drop(columns=['Attack Type']).copy(),\n",
        "        moved_to_test.drop(columns=['Attack Type']).copy()\n",
        "    ], ignore_index=True)\n",
        "    y_test_full = pd.concat([\n",
        "        y_test.copy().reset_index(drop=True),\n",
        "        moved_to_test_y.copy().reset_index(drop=True)\n",
        "    ], ignore_index=True)\n",
        "\n",
        "    # checar duplicatas exatas (linhas idênticas) no conjunto zero-day\n",
        "    n_dupes = X_test_zero_day.duplicated().sum()\n",
        "    print(f\"  Zero-Day combined total: {len(X_test_zero_day)} (duplicadas exatas: {n_dupes})\")\n",
        "    print(f\"  Test full total: {len(X_test_full)}\")\n",
        "\n",
        "    # extra debug: se houver muito mais que o total original, alerta\n",
        "    if len(X_test_zero_day) > total_in_original:\n",
        "        print(f\"[WARNING] mais amostras zero-day no teste ({len(X_test_zero_day)}) do que no dataset original ({total_in_original}). Verifique possíveis fontes de duplicação ou rótulos desiguais.\")\n",
        "\n",
        "    # --- Balanceamento com SMOTE ---\n",
        "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train_clean, y_train_clean)\n",
        "\n",
        "    # --- Normalização ---\n",
        "    X_train_scaled = scaler.fit_transform(X_train_balanced)\n",
        "    X_test_full_scaled = scaler.transform(X_test_full)\n",
        "    X_test_zero_day_scaled = scaler.transform(X_test_zero_day)\n",
        "\n",
        "    # =============================\n",
        "    # Codificação dos rótulos\n",
        "    # =============================\n",
        "    le = LabelEncoder()\n",
        "    y_train_encoded = le.fit_transform(y_train_balanced)\n",
        "    y_test_full_encoded = le.transform(y_test_full)\n",
        "    y_test_zero_day_encoded = le.transform(y_test_zero_day)\n",
        "\n",
        "    # =============================\n",
        "    # Treinamento do modelo\n",
        "    # =============================\n",
        "    model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "    recursos_rf = monitor_train_generic(model, X_train_scaled, y_train_encoded, \"Random Forest\")\n",
        "\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_encoded)\n",
        "\n",
        "    # TESTE GERAL COM MONITORAMENTO\n",
        "    # =============================\n",
        "    mstart_time = time.time()\n",
        "    y_pred_full = model.predict(X_test_full_scaled)\n",
        "    y_pred_full_encoded = le.transform(y_pred_full)\n",
        "    metrics_test_full = monitor_test_prediction(model, X_test_full_scaled)\n",
        "    acc_teste_full = accuracy_score(y_test_full_encoded, y_pred_full_encoded)\n",
        "    f1_teste_full = f1_score(y_test_full_encoded, y_pred_full_encoded, zero_division=1)\n",
        "    precision_full = precision_score(y_test_full_encoded, y_pred_full_encoded, zero_division=1)\n",
        "    recall_full = recall_score(y_test_full_encoded, y_pred_full_encoded, zero_division=1)\n",
        "\n",
        "\n",
        "    # =============================\n",
        "    # TESTE ZERO-DAY COM MONITORAMENTO\n",
        "    # =============================\n",
        "    start_time = time.time()\n",
        "    y_pred_zero_day = model.predict(X_test_zero_day_scaled)\n",
        "    y_pred_zero_day_encoded = le.transform(y_pred_zero_day)\n",
        "    metrics_zero_day = monitor_test_prediction(model, X_test_zero_day_scaled)\n",
        "    acc_zero_day = accuracy_score(y_test_zero_day_encoded, y_pred_zero_day_encoded)\n",
        "    f1_zero_day = f1_score(y_test_zero_day_encoded, y_pred_zero_day_encoded, zero_division=1)\n",
        "    precision_zero = precision_score(y_test_zero_day_encoded, y_pred_zero_day_encoded, zero_division=1)\n",
        "    recall_zero = recall_score(y_test_zero_day_encoded, y_pred_zero_day_encoded, zero_division=1)\n",
        "\n",
        "    # =============================\n",
        "    # Salvar resultados\n",
        "    # =============================\n",
        "    resultados_zero_day.append({\n",
        "    'Ataque Zero-Day': ataque_zero_day,\n",
        "\n",
        "    'Acurácia': acc_teste_full,\n",
        "    'F1': f1_teste_full,\n",
        "    'Precision': precision_full,\n",
        "    'Recall': recall_full,\n",
        "    'Tempo de Teste': metrics_test_full['total_time'],\n",
        "    'CPU Teste': metrics_test_full['avg_cpu'],\n",
        "    'Memória Teste': metrics_test_full['avg_mem'],\n",
        "    'Energia Teste': metrics_test_full['energia'],\n",
        "\n",
        "    'ZD - Acurácia': acc_zero_day,\n",
        "    'ZD- F1': f1_zero_day,\n",
        "    'ZD - Precision': precision_zero,\n",
        "    'ZD - Recall': recall_zero,\n",
        "    'ZD - Tempo de Teste': metrics_zero_day['total_time'],\n",
        "    'ZD - CPU Teste': metrics_zero_day['avg_cpu'],\n",
        "    'ZD - Memória Teste': metrics_zero_day['avg_mem'],\n",
        "    'ZD - Energia Teste': metrics_zero_day['energia'],\n",
        "})\n",
        "    # =============================\n",
        "    # CURVA ROC (gerada no mesmo loop)\n",
        "    # =============================\n",
        "    # TESTE FULL\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        probs_full = model.predict_proba(X_test_full_scaled)[:, 1]\n",
        "    elif hasattr(model, \"decision_function\"):\n",
        "        probs_full = model.decision_function(X_test_full_scaled)\n",
        "    else:\n",
        "        raise AttributeError(f\"O modelo {model.__class__.__name__} não possui predict_proba nem decision_function.\")\n",
        "\n",
        "    fpr_full, tpr_full, _ = roc_curve(y_test_full_encoded, probs_full)\n",
        "    roc_auc_full = auc(fpr_full, tpr_full)\n",
        "\n",
        "    # Guarda a curva na lista (com label do ataque)\n",
        "    roc_full_curves.append((fpr_full, tpr_full, roc_auc_full, f\"{ataque_zero_day}\"))\n",
        "\n",
        "    print(f\"✅ Curva ROC (FULL) gerada para {ataque_zero_day} — AUC={roc_auc_full:.4f}\")\n",
        "\n",
        "    del model\n",
        "    gc.collect()\n",
        "    K.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Após o loop, gera um gráfico com todas as curvas FULL\n",
        "# =========================================\n",
        "plt.figure(figsize=(10, 7))\n",
        "colors = plt.cm.get_cmap('tab10', len(roc_full_curves))\n",
        "\n",
        "for i, (fpr, tpr, auc_val, label) in enumerate(roc_full_curves):\n",
        "    plt.plot(fpr, tpr, lw=3, color=colors(i), label=f\"{label} (AUC={auc_val:.4f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=1)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title(f'ROC Curves FULL — {model_name}')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "os.makedirs(\"roc_curves\", exist_ok=True)\n",
        "plt.savefig(f\"roc_curves/{model_name}_ALL_FULL_ROC.png\", dpi=400)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-lXSv0dTH4Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bbc578f"
      },
      "outputs": [],
      "source": [
        "!pip install tabulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMggcV4MZvLl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "df_resultados = pd.DataFrame(resultados_zero_day)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 180)\n",
        "pd.set_option('display.float_format', '{:.4f}'.format)\n",
        "\n",
        "print(tabulate(df_resultados, headers='keys', tablefmt='fancy_grid', showindex=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqQFSN5gm0hA"
      },
      "outputs": [],
      "source": [
        "df_resultados.to_csv('resultados_zero_day_formatado.csv', index=False, float_format='%.4f')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}